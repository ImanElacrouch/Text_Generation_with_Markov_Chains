{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c04862e",
   "metadata": {},
   "source": [
    "# Text Generation with Markov Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46720607",
   "metadata": {},
   "source": [
    "Markov chains are a mathematical concept used to model systems that transition from one state to another, where the probability of each subsequent state depends only on the current state and not on the sequence of events that preceded it. In the context of text generation, Markov chains can be used to generate sequences of text that resemble the style and structure of a given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c83051",
   "metadata": {},
   "source": [
    "SIMPLE EXAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fff1c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Sample text\n",
    "text = \"A Markov chain process is a stochastic model describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "255060f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "words = text.split()\n",
    "word_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4344c861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Markov chain\n",
    "for i in range(len(words) - 1):\n",
    "    if words[i] in word_dict:\n",
    "        word_dict[words[i]].append(words[i + 1])\n",
    "    else:\n",
    "        word_dict[words[i]] = [words[i + 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "555f03b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markov chain process is a stochastic model describing a stochastic model describing a stochastic model describing\n"
     ]
    }
   ],
   "source": [
    "# Generate text\n",
    "current_word = \"Markov\"\n",
    "output = [current_word]\n",
    "\n",
    "for _ in range(15):\n",
    "    next_word = random.choice(word_dict[current_word])\n",
    "    output.append(next_word)\n",
    "    current_word = next_word\n",
    "\n",
    "generated_text = \" \".join(output)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fee109",
   "metadata": {},
   "source": [
    "This code initializes the Markov chain with the sample text and generates a sequence of 15 words starting with \"Markov\".\n",
    "\n",
    "Markov chains can produce coherent and contextually relevant text sequences, making them useful for text generation, predictive text applications, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ea1436",
   "metadata": {},
   "source": [
    "### Exploring the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a9a706",
   "metadata": {},
   "source": [
    "The code in the following cell loads into Python variables the contents of two plain text files, assigned to variables text_a and text_b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0efb29eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_a = open(\"data_science.txt\").read()\n",
    "text_b = open(\"AI.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "062a278c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data science is an interdisciplinary field that leverages various techniques and principles from statistics, computer science, and domain-specific expertise to extract actionable insights from vast and complex datasets. \n"
     ]
    }
   ],
   "source": [
    "print(text_a[:220])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01b7ac79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence (AI) is a broad and dynamic field that focuses on creating systems capable of performing tasks that typically require human intelligence. These tasks include learning, reasoning, problem-solving, \n"
     ]
    }
   ],
   "source": [
    "print(text_b[:220])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3257d4e4",
   "metadata": {},
   "source": [
    "The random.sample() function gives us a random sampling of the contents of a variable (as long as that variable is a sequence of things, like a string or a list). So, for example, to see twenty random characters from text B:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0355f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['z', ' ', 'm', 't', 'm', 'e', 'o', 'a', 'e', 't']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.sample(text_b, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fed4a910",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_words = text_a.split()\n",
    "b_words = text_b.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7932ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['science',\n",
       " 'analysis',\n",
       " 'handling',\n",
       " 'driving.',\n",
       " 'being',\n",
       " 'of',\n",
       " 'data',\n",
       " 'tools',\n",
       " 'hidden',\n",
       " 'their']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(a_words, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dc0703f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['their',\n",
       " 'approach',\n",
       " 'can',\n",
       " 'object',\n",
       " 'and',\n",
       " 'optimized',\n",
       " 'Amazon,',\n",
       " 'of',\n",
       " 'like',\n",
       " 'would']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(b_words, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bc89c8",
   "metadata": {},
   "source": [
    "The code in the following cell uses Python's Counter object to count the most common letters in the first of these texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b688bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' ', 858),\n",
       " ('e', 566),\n",
       " ('a', 496),\n",
       " ('i', 465),\n",
       " ('n', 446),\n",
       " ('t', 394),\n",
       " ('s', 380),\n",
       " ('o', 309),\n",
       " ('r', 292),\n",
       " ('d', 249)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(text_a).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a693d0d",
   "metadata": {},
   "source": [
    "Specifying the a_words variable gives the most frequent words instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5026bf43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('and', 47),\n",
       " ('data', 37),\n",
       " ('the', 33),\n",
       " ('of', 27),\n",
       " ('to', 21),\n",
       " ('is', 20),\n",
       " ('a', 17),\n",
       " ('science', 13),\n",
       " ('in', 11),\n",
       " ('for', 10)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(a_words).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6beb349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('and', 49),\n",
       " ('to', 29),\n",
       " ('of', 26),\n",
       " ('AI', 25),\n",
       " ('the', 20),\n",
       " ('is', 15),\n",
       " ('a', 13),\n",
       " ('with', 11),\n",
       " ('that', 10),\n",
       " ('as', 10)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(b_words).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063ad49b",
   "metadata": {},
   "source": [
    "### Markov models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bf5272",
   "metadata": {},
   "source": [
    "Markov models are mathematical frameworks that predict the future state of a system based on its current state, assuming that the future state depends only on the present state and not on the sequence of events that preceded it. They are used to model random processes and are commonly applied in fields like speech recognition, economics, and biology. The key concept is the \"memoryless\" property, meaning the next state is determined solely by the current state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5387e4",
   "metadata": {},
   "source": [
    "## N-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216f7e3e",
   "metadata": {},
   "source": [
    "N-grams are sequences of units (like characters or words) from a larger sequence. The \"level\" refers to the unit type (character or word), and the \"order\" refers to the length of the n-gram. For example, in the word \"intelligence,\" all unique character-level order-2 n-grams are:\n",
    "* in\n",
    "* te\n",
    "* ll\n",
    "* ig\n",
    "* en\n",
    "* ce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf8d31c",
   "metadata": {},
   "source": [
    "N-grams are used in natural language processing for tasks like spelling correction, text analysis, compression algorithms, and generative text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21661747",
   "metadata": {},
   "source": [
    "### Generating text from a Markov model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59cc87a",
   "metadata": {},
   "source": [
    "A Markov model extends the n-gram concept by tracking what units follow each n-gram. For example, in \"intelligence,\" the n-gram \"in\" is always followed by \"t,\" while \"te\" is followed by \"l\" or \"l.\"\n",
    "\n",
    "To generate text using a Markov model, start with an initial n-gram, and then iteratively choose the next unit based on the probabilities from the model. This process creates a new sequence that statistically resembles the original input. This technique is known as a Markov chain generator. For example, using the order-2 character-level Markov model of \"intelligence,\" the generated text might be:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba5b746",
   "metadata": {},
   "source": [
    "* in\n",
    "* int\n",
    "* inte\n",
    "* intel\n",
    "* intell\n",
    "* intelli\n",
    "* intellig\n",
    "* intellige\n",
    "* intelligen\n",
    "* intelligence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069adb76",
   "metadata": {},
   "source": [
    "This results in a sequence similar to the original word, illustrating the Markov chain process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082dc02c",
   "metadata": {},
   "source": [
    "### Generating with Markovify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61a598db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: markovify in c:\\users\\user\\anaconda3\\lib\\site-packages (0.9.4)\n",
      "Requirement already satisfied: unidecode in c:\\users\\user\\anaconda3\\lib\\site-packages (from markovify) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "#install Markovify\n",
    "import sys\n",
    "!{sys.executable} -m pip install markovify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccdcc0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import markovify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e77ca3",
   "metadata": {},
   "source": [
    "Creating a new text generator, using the text in the variable specified to build the Markov model, which is then assigned to the variable generator_a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec7a0b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_a = markovify.Text(text_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570e1bfd",
   "metadata": {},
   "source": [
    "Generate a sentence from the model using \".make_sentence()\" method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b03289c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The primary objective of data and complex patterns.\n"
     ]
    }
   ],
   "source": [
    "print(generator_a.make_sentence())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40f7abe",
   "metadata": {},
   "source": [
    "The \".make_short_sentence()\" method allows you to specify a maximum length for the generated sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2060da",
   "metadata": {},
   "source": [
    "### Changing the order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49e7fb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_a_1 = markovify.Text(text_a, state_size=1)\n",
    "gen_a_4 = markovify.Text(text_a, state_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e9ca72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order 1\n",
      "Supervised learning involves training a distributed computing environment.\n",
      "\n",
      "order 4\n",
      "Supervised learning involves training a model on labeled data, where the target variable is known, to make predictions on new, unseen data.\n"
     ]
    }
   ],
   "source": [
    "print(\"order 1\")\n",
    "print(gen_a_1.make_sentence(test_output=False))\n",
    "print()\n",
    "print(\"order 4\")\n",
    "print(gen_a_4.make_sentence(test_output=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c70ab4",
   "metadata": {},
   "source": [
    "In general, the higher the order, the more the sentences will seem \"coherent\" (i.e., more closely resembling the source text). Lower order models will produce more variation. \n",
    "Deciding on the order is usually a matter of trial-and-error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262b3fb7",
   "metadata": {},
   "source": [
    "### Changing the level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d9cdc3",
   "metadata": {},
   "source": [
    "Markovify, by default, works with words as the individual unit. It doesn't come out-of-the-box with support for character-level models. \n",
    "The following code defines a new kind of Markovify generator that implements character-level models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "263d6ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentencesByChar(markovify.Text):\n",
    "    def word_split(self, sentence):\n",
    "        return list(sentence)\n",
    "    def word_join(self, words):\n",
    "        return \"\".join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09decd25",
   "metadata": {},
   "source": [
    "Any of the parameters you passed to markovify.Text you can also pass to SentencesByChar. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653c0eab",
   "metadata": {},
   "source": [
    "The state_size parameter still controls the order of the model, but now the n-grams are characters, not words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47d3ba8",
   "metadata": {},
   "source": [
    "The following cell creates a character-level order-7 Markov chain text generator from text A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b243e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_a_char = SentencesByChar(text_a, state_size=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60e4befd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDA helps in identifying patterns, correlations, and inconsistencies.\n"
     ]
    }
   ],
   "source": [
    "print(gen_a_char.make_sentence(test_output=False).replace(\"\\n\", \" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f5c02c",
   "metadata": {},
   "source": [
    "### Combining models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69924b54",
   "metadata": {},
   "source": [
    "Markovify has a handy feature that allows you to combine models, creating a new model that draws on probabilities from both of the source models.<br>\n",
    "To do this, we need to create the models independently, and then call \".combine()\" to combine them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b162f188",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_a = markovify.Text(text_a)\n",
    "generator_b = markovify.Text(text_b)\n",
    "combo = markovify.combine([generator_a, generator_b], [0.5, 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3213945c",
   "metadata": {},
   "source": [
    "The bit of code [0.5, 0.5] controls the \"weights\" of the models, i.e., how much to emphasize the probabilities of any model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4bdd48af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI is computer vision, which aims to enable machines to possess consciousness, self-awareness, and a deep understanding of context and nuance.\n"
     ]
    }
   ],
   "source": [
    "print(combo.make_sentence())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55baa372",
   "metadata": {},
   "source": [
    "### Bringing it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a26f9fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to \"word\" for a word-level model\n",
    "level = \"word\"\n",
    "# controls the length of the n-gram\n",
    "order = 7\n",
    "# controls the number of lines to output\n",
    "output_n = 14\n",
    "# weights between the models; text A first, text B second.\n",
    "weights = [0.5, 0.5]\n",
    "# limit sentence output to this number of characters\n",
    "length_limit = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "57ebeba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In healthcare, AI is used for diagnosing diseases, personalized treatment planning, and drug discovery.\n",
      "\n",
      "Ensuring that AI systems are transparent, fair, and accountable is essential for fostering trust and preventing harm.\n",
      "\n",
      "As research and development continue to advance, the future of AI promises to bring about unprecedented innovations and opportunities.\n",
      "\n",
      "Data science has a wide range of applications across different industries.\n",
      "\n",
      "General AI, or strong AI, refers to systems that possess the ability to understand, learn, and apply knowledge across a broad range of tasks, much like a human being.\n",
      "\n",
      "In healthcare, data science is revolutionizing personalized medicine, predictive analytics, and the discovery of new drugs.\n",
      "\n",
      "Ensuring that AI systems are transparent, fair, and accountable is essential for fostering trust and preventing harm.\n",
      "\n",
      "Applications of NLP include machine translation, sentiment analysis, chatbots, and voice assistants.\n",
      "\n",
      "It encompasses a wide range of techniques and technologies aimed at extracting insights from data, driving innovation, and solving complex problems across various domains.\n",
      "\n",
      "Another critical aspect of data science is big data, which refers to the analysis of datasets that are too large or complex for traditional data-processing software.\n",
      "\n",
      "Advances in NLP have led to the development of sophisticated models like OpenAI's GPT-3, which can generate human-like text based on a given prompt.\n",
      "\n",
      "Data science has a wide range of applications across various industries.\n",
      "\n",
      "EDA helps in identifying patterns, correlations, and anomalies, which can provide valuable insights even before any predictive modeling is applied.\n",
      "\n",
      "Data science has a wide range of applications across different industries.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_cls = markovify.Text if level == \"word\" else SentencesByChar\n",
    "\n",
    "gen_a = model_cls(text_a, state_size=order)\n",
    "gen_b = model_cls(text_b, state_size=order)\n",
    "\n",
    "gen_combo = markovify.combine([gen_a, gen_b], weights)\n",
    "\n",
    "for i in range(output_n):\n",
    "    out = gen_combo.make_short_sentence(length_limit, test_output=False)\n",
    "    out = out.replace(\"\\n\", \" \")\n",
    "    print(out)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a0f5bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761403cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
